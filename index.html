<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Dominik Stöger</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="home_dominik.html" class="current">Home</a></div>
<div class="menu-item"><a href="publications_dominik.html">Publications</a></div>
<div class="menu-item"><a href="talks.html">Talks</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Dominik Stöger</h1>
</div>
<table class="imgtable"><tr><td>
<a href="dominiks_new.jpeg"><img src="dominiks_new.jpeg" alt="Dominik" width="320px" height="266px" /></a>&nbsp;</td>
<td align="left"><p>Dominik Stöger
</p>
<p>KU Eichstätt-Ingolstadt<br />
MIDS (Mathematical Institute for Data Science and Machine Learning)<br />
Assistant Professor (tenure-track)
</p>
<p>Email: <a href="mailto:Dominik.Stoger@ku.de" target=&ldquo;blank&rdquo;>Dominik.Stoeger@ku.de</a> <br />
<a href="https://scholar.google.com/citations?user=-aLITVUAAAAJ" target=&ldquo;blank&rdquo;>Google Scholar</a>
</p>
</td></tr></table>
<p><br />
Since 2021, I have been an Assistant Professor (tenure-track) at KU Eichstätt-Ingolstadt at the Department of Mathematics, affiliated with <a href="https://www.ku.de/en/mids" target=&ldquo;blank&rdquo;>MIDS</a>. Before this role, I was a postdoctoral researcher at USC from 2019 to 2021, where I was mentored by <a href="https://viterbi-web.usc.edu/~soltanol/" target=&ldquo;blank&rdquo;>Mahdi Soltanolkotabi</a>. I completed my Ph.D. in Mathematics at the Technical University of Munich in 2019 under the supervision of <a href="https://www.math.cit.tum.de/math/personen/professuren/krahmer-felix/" target=&ldquo;blank&rdquo;>Felix Krahmer</a>.  I also obtained my MSc and BSc degrees in Mathematics from the Technical University of Munich in 2015 and 2013, respectively.
</p>
<p>My research interests lie in the mathematical foundations of data science. These include non-convex optimization problems in machine learning and signal processing, understanding overparameterization in modern machine learning models, and low-rank matrix recovery problems. To study these topics I often combine tools from optimization and high-dimensional probability. 
</p>
<p>A longer  CV can be found <a href="./scientific_cv.pdf" target=&ldquo;blank&rdquo;>here</a> (last updated May 2024).
</p>
<h2>News:</h2>
<ul>
<li><p>06/2025: new preprint <a href="https://arxiv.org/abs/2506.01143" target=&ldquo;blank&rdquo;>Linear regression with overparameterized linear neural networks: Tight upper and lower bounds for implicit l1-regularization</a> joint with Hannes Matt
</p>
</li>
<li><p>05/2025: the paper <a href="https://www.arxiv.org/abs/2408.13276" target=&ldquo;blank&rdquo;>Non-convex matrix sensing:  Breaking the quadratic rank barrier in the sample complexity</a> joint with <a href="https://sites.google.com/usc.edu/yizhezhu" target=&ldquo;blank&rdquo;>Yizhe Zhu</a> was accepted in <a href="https://learningtheory.org/colt2025/" target=&ldquo;blank&rdquo;>COLT 2025</a>
</p>
</li>
<li><p>11/2023: new preprint <a href="https://arxiv.org/abs/2311.01356" target=&ldquo;blank&rdquo;>On the Lipschitz constant of random neural networks</a> joint with Paul Geuchen, Thomas Heindl, and <a href="https://voigtlaender.xyz" target=&ldquo;blank&rdquo;>Felix Voigtlaender</a>
</p>
</li>
<li><p>06/2023: my paper on <a href="https://arxiv.org/abs/2206.00803" target=&ldquo;blank&rdquo;>Robust recovery of low-rank matrices and low-tubal-rank tensors from noisy sketches</a>, joint  with <a href="https://sites.google.com/view/annama" target=&ldquo;blank&rdquo;>Anna Ma</a> and <a href="https://sites.google.com/uci.edu/yizhezhu" target=&ldquo;blank&rdquo;>Yizhe Zhu</a>, was accepted for publication by the <a href="https://www.siam.org/publications/journals/siam-journal-on-matrix-analysis-and-applications-simax" target=&ldquo;blank&rdquo;>SIAM Journal on Matrix Analysis and Applications</a>
</p>
</li>
<li><p>05/2023: my paper  on <a href="https://arxiv.org/abs/2303.14244" target=&ldquo;blank&rdquo;>Implicit Balancing and Regularization: Generalization and Convergence Guarantees for Overparameterized Asymmetric Matrix Sensing</a> with <a href="https://viterbi-web.usc.edu/~soltanol/" target=&ldquo;blank&rdquo;>Mahdi Soltanolkotabi</a> and <a href="https://scholar.google.com/citations?user=k-kAoPEAAAAJ" target=&ldquo;blank&rdquo;>Changzhi Xie</a> was accepted for publication  in <a href="https://learningtheory.org/colt2023/index.html" target=&ldquo;blank&rdquo;>COLT 2023</a>
</p>
</li>
<li><p>04/2023: my paper on <a href="https://arxiv.org/abs/2204.11516" target=&ldquo;blank&rdquo;>Randomly Initialized Alternating Least Squares: Fast Convergence for Matrix Sensing</a>, joint with <a href="https://u.osu.edu/kiryung/" target=&ldquo;blank&rdquo;>Kiryung Lee</a>, was accepted for publication by the SIAM Journal on Mathematics of Data Science
</p>
</li>
<li><p>03/2023: new preprint on <a href="https://arxiv.org/abs/2303.10030" target=&ldquo;blank&rdquo;>How robust is randomized blind deconvolution via nuclear norm minimization against adversarial noise?</a> with <a href="https://juliakostin.github.io" target=&ldquo;blank&rdquo;>Julia Kostin</a> and <a href="https://www.math.cit.tum.de/math/personen/professuren/krahmer-felix/" target=&ldquo;blank&rdquo;>Felix Krahmer</a>
</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2025-06-03 10:51:45 CEST, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Publications</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="home_dominik.html">Home</a></div>
<div class="menu-item"><a href="publications_dominik.html" class="current">Publications</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Publications</h1>
</div>
<h2>Preprints:</h2>
<ol>
<li><p>H. Chou, J. Maly, and D. Stöger. How to induce regularization in generalized linear models: A guide to reparametrizing gradient flow<br />
<a href="https://arxiv.org/abs/2308.04921">[preprint]</a></p>
</li>
<li><p>J. Kostin, F. Krahmer, and D. Stöger. How robust is randomized blind deconvolution via nuclear norm minimization against adversarial noise?<br />
<a href="https://arxiv.org/abs/2303.10030">[preprint]</a></p>
</li>
</ol>
<h2>Long papers in selective conferences:</h2>
<ol>
<li><p>M. Soltanolkotabi, D. Stöger, C. Xie. Implicit Balancing and Regularization: Generalization and Convergence Guarantees for Overparameterized Asymmetric Matrix Sensing.<br />
<i>accepted in <a href="https://learningtheory.org/colt2023/index.html">COLT 2023</a></i> <br />
<a href="https://arxiv.org/abs/2303.14244">[preprint]</a></p>
</li>
<li><p>D. Stöger and M. Soltanolkotabi. Small random initialization is akin to spectral learning: Optimization and generalization guarantees for overparameterized low-rank matrix reconstruction. <br /> 
<i>NeurIPS 2021</i> <br />
<a href="https://arxiv.org/abs/2106.15013">[full paper]</a> <a href="https://papers.nips.cc/paper/2021/hash/c82836ed448c41094025b4a872c5341e-Abstract.html">[NeurIPS version]</a></p>
</li>
<li><p>C. Kümmerle, C. Mayrink Verdun, and D. Stöger. Iteratively Reweighted Least Squares for Basis Pursuit with Global Linear Convergence Rate.<br />
<i>NeurIPS 2021 (Spotlight, top 3% of submitted papers)</i> <br />
<a href="https://arxiv.org/abs/2012.12250">[full paper]</a> <a href="https://proceedings.neurips.cc/paper/2021/hash/16bda725ae44af3bb9316f416bd13b1b-Abstract.html">[NeurIPS version]</a>  </p>
</li>
<li><p>Y. Balaji, M. Sajedi, N. Kalibhat, M. Ding, D. Stöger, M. Soltanolkotabi, S. Feizi. Understanding Over-parameterization in Generative Adversarial Networks. <br />
<i>ICLR 2021</i> <br />
<a href="https://openreview.net/pdf?id=C3qvk5IQIJY">[Paper]</a></p>
</li>
</ol>
<h2>Refereed Journal articles:</h2>
<ol>
<li><p>A. Ma, D. Stöger, and Y. Zhu. Robust recovery of low-rank matrices and low-tubal-rank tensors from noisy sketches<br />
<i>to appear in SIAM Journal on Matrix Analysis and Applications (SIMAX)</i> <br />
<a href="https://arxiv.org/abs/2206.00803">[preprint]</a></p>
</li>
<li><p>K. Lee and D. Stöger. Randomly Initialized Alternating Least Squares: Fast Convergence for Matrix Sensing.<br />
<i>SIAM Journal on Mathematics of Data Science (SIMODS), 2023</i> <br />
<a href="http://arxiv.org/abs/2204.11516">[preprint]</a> <a href="https://epubs.siam.org/eprint/SC8PFZVEWMEAWN4PIQBI/full">[Journal]</a></p>
</li>
<li><p>F. Krahmer and D. Stöger. On the convex geometry of blind deconvolution and matrix completion.<br /> 
<i>Communications on Pure and Applied Mathematics, 2021</i> <br />
<a href="https://arxiv.org/abs/1902.11156">[preprint]</a> <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.21957">[Journal]</a></p>
</li>
<li><p>F. Krahmer and D. Stöger. Complex phase retrieval from subgaussian measurements. <br />
<i>Journal of Fourier Analysis and Applications, 2020</i> <br />
<a href="https://arxiv.org/abs/1906.08385">[preprint]</a> <a href="https://link.springer.com/article/10.1007/s00041-020-09797-9">[Journal]</a></p>
</li>
<li><p>F. Cagnetti, M. Perugini, and D. Stöger. Rigidity for perimeter inequality under spherical symmetrisation<br />
<i>In: Calculus of Variations and Partial Differential Equations, 2020</i> <br />
<a href="https://arxiv.org/abs/1908.04865">[preprint]</a> <a href="https://link.springer.com/article/10.1007/s00526-020-01786-6">[Journal]</a></p>
</li>
<li><p>J. Geppert, F. Krahmer, and D. Stöger. Sparse Power Factorization: Balancing peakiness and sample complexity.<br /> 
<i>Advances in Computational Mathematics, 2019.</i> <br />
<a href="https://arxiv.org/abs/1804.09097">[preprint]</a> <a href="https://link.springer.com/article/10.1007/s10444-019-09698-6">[Journal]</a></p>
</li>
<li><p>P. Jung, F. Krahmer, and D. Stöger. Blind demixing and deconvolution at near-optimal rate. <br /> 
<i>IEEE Transactions on Information Theory, 2018</i> <br /> <a href="https://arxiv.org/abs/1704.04178">[preprint]</a> <a href="https://ieeexplore.ieee.org/document/8240933/">[Journal]</a></p>
</li>
</ol>
<h2>Book Chapters:</h2>
<ol>
<li><p>T. Fuchs, D. Gross, P. Jung, F. Krahmer, R. Kueng, Dominik Stöger. Proof methods for robust low-rank matrix recovery<br />
<i>Compressed Sensing in Information Processing. Birkhäuser, Cham, 2022. 37-75.</i> <br />
<a href="https://link.springer.com/chapter/10.1007/978-3-031-09745-4_2">[Book chapter]</a><a href="https://arxiv.org/abs/2106.04382">[arXiv]</a></p>
</li>
</ol>
<h2>Conference proceedings:</h2>
<ol>
<li><p>F. Krahmer and D. Stöger. “Blind deconvolution: Convex geometry and noise robustness”. In: 52nd Annual Asilomar Conference on Signals, Systems, and Computers. IEEE. 2018.</p>
</li>
<li><p>D. Stöger, J. Geppert, and F. Krahmer. “Sparse power factorization with refined peakiness conditions”. In: 2018 IEEE Statistical Signal Processing Workshop (SSP). IEEE. 2018, pp. 816–820.</p>
</li>
<li><p>J. Geppert, F. Krahmer, and D. Stöger. “Refined performance guarantees for Sparse Power Factorization”. In: 12th International Conference on Sampling Theory and Applications (SampTA). IEEE. 2017, pp. 509–513.</p>
</li>
<li><p>D. Stöger, P. Jung, and F. Krahmer. “Blind demixing and deconvolution with noisy data at near optimal rate”. In: Wavelets and Sparsity XVII. Vol. 10394. International Society for Optics and Photonics. 2017, 103941E.</p>
</li>
<li><p>P. Jung, F. Krahmer, and D. Stoeger. “Blind Demixing and Deconvolution with Noisy Data: Near-optimal Rate”. In: 21st International ITG Workshop on Smart Antenna. 2017.</p>
</li>
<li><p>D. Stöger, P. Jung, and F. Krahmer. “Blind deconvolution and compressed sensing”. In: 2016 4th International Workshop on Compressed Sensing Theory and its Applications to Radar, Sonar and Remote Sensing (CoSeRa). IEEE. 2016, pp. 24–27</p>
</li>
</ol>
<div id="footer">
<div id="footer-text">
Page generated 2023-09-06 15:29:14 CEST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
